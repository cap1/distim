\section{Local Replication} % (fold)
\label{sec:local_replication}

\subsection{Research various techniques used to ensure consistency of a local replica.} % (fold)
\label{sub:research_various_techniques_used_to_ensure_consistency_of_a_local_replica}
	The easiest way to ensure consistency when performing a replication
	is to hold all I/O to the data.
	This is not always possible as,
	request might time out.
	However one can be sure that at the end of the replication,
	the data is correctly replicated.
	If this technique is applicable depends on the time it
	takes to perform the replication.

	As I/O depends usually on a previous set of I/Os
	it is also possible to capture all I/Os that occurred during the replication.
	These I/Os are then also performed on the replica.
	This ensures that data is still accessible and writable,
	but the replica equals the data at the point in time
	when the replica is finished.
	One has to make sure to perform all dependent I/Os
	and apply them in the correct order.
% subsection research_various_techniques_used_to_ensure_consistency_of_a_local_replica (end)

\subsection{Describe local replication technologies!} % (fold)
\label{sub:describe_local_replication_technologies}

	\subsubsection{Host-based replication} % (fold)
	\label{ssub:host_based_replication}
		\begin{description}
			\item[LVM-based replication] \hfill \\
				The logical volume managers takes care for creating host-level logical volumes.
				In a LVM-based replication,
				each logical block in a logical volume is mapped to two physical blocks
				on two different physical volumes.
				An Application writing to a logical block now writes to two physical blocks.
				This is known as \emph{LVM Mirroring}.

				It adds some workload to the hosts CPU
				and if the devices are already protected by a RAID
				no addition protection is installed.
				An advantage is the vendor independence
				and as LVMs are usually part of the OS no additional licensing is necessary.
			\item[File-System snapshot] \hfill \\
				This FS snapshot is a pointer based replica,
				that can be implemented either on the FS or LVM level
				and uses the Copy on First Write (CoFW) principle to create the snapshots.
				It just requires a fraction of the space used by the production FS.

				When a snapshot is created,
				a bit and a blockmap are created in the metadata of the Snap FS.
				When a write occurs on the production FS this is held.
				The data previously on this position is copied to the Snap FS.
				The new data on this position is then copied to the Snap FS.
				The block and the bit map are changed to represent which data is stored.
				Then the I/Os goes to the production OS.
				%O RLY?
		\end{description}
	% subsubsection host_based_replication (end)

	\subsubsection{Storage Array-based local replication} % (fold)
	\label{ssub:storage_array_based_local_replication}
		The array operating environment takes care of the replication process.
		The replica is located in the same place as the source.
		After the replication the replica is accessible by an alternative host.

		\begin{description}
			\item[Full-Volume mirroring] \hfill \\
				The source gets copied to the target (the replica).
				New updates on the source are also performed on the target.
				After finishing the replication the target can be detached from the source.
			\item[Pointer-based full-volume replication] \hfill \\
				The Point in time to which this replica corresponds is the time 
				the replication is initiated.
				In \emph{Copy on First Access} (CoFA) the data is copied to the replica,
				if any changes are made to the production host.
				The data that is accessed or should be overwritten is the send to
				the replica.

				Instead of the lazy CoFA approach,
				one can also copy the source in the background.
				If I/O occurs on a block that has not been copied yet,
				this block is copied preferentially.
				This \emph{Full Copy} mode requires the replica to be as large
				as the production volume.
			\item[Pointer-based virtual replication] \hfill \\
				Uses a virtual device that uses pointer to a save location.
		\end{description}
	% subsubsection storage_array_based_local_replication (end)

\subsection{Research continuous data protection technology and its benefits over array-based replication technologies.} % (fold)
\label{sub:research_continuous_data_protection_technology_and_its_benefits_over_array_based_replication_technologies}
	Continuous data protection (CDP) ensures a quick recovery
	in the case of data loss or corruption.
	Technologies RAID do not ensure that the data to recover to is valid.
	If there is any logical corruption,
	it is likely that it will spread to the mirrors.

	Continuous data protection works using a write splitter
	and a CDP appliance.
	When data is changed,
	the write splitter duplicates the I/O 
	and sends one to the production volume
	and the other one to the CDP appliance.
	The CDP appliance logs all changes to the data
	in a CDP journal along with a timestamp.
	Depending on the size of the journal,
	one can revert to all the changes that are still present in the journal.\\
	To a replica,
	that hast been generated before the CDP sessions started,
	the recorded changes are send in regular intervals.
% subsection research_continuous_data_protection_technology_and_its_benefits_over_array_based_replication_technologies (end)

% section local_replication (end)